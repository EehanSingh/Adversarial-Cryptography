{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GANSproject.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"m2zfZMjQM4jB","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","import signal\n","import sys\n","from six.moves import xrange  # pylint: disable=redefined-builtin\n","import tensorflow as tf\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uZVj6nBPM5ow","colab_type":"code","outputId":"7882fcb4-2392-4c21-c97a-808b00c91171","executionInfo":{"status":"error","timestamp":1556536688307,"user_tz":-330,"elapsed":2040,"user":{"displayName":"Eeshan Singh","photoUrl":"https://lh3.googleusercontent.com/-QZFb7ryZVUw/AAAAAAAAAAI/AAAAAAAAACQ/hhmr0CU72zU/s64/photo.jpg","userId":"14161015115537070471"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"cell_type":"code","source":["\n","\n","\n","flags = tf.app.flags\n","\n","flags.DEFINE_float('learning_rate', 0.0008, 'Constant learning rate')\n","flags.DEFINE_integer('batch_size', 4096, 'Batch size')\n","\n","FLAGS = flags.FLAGS\n","\n","# Input and output configuration.\n","TEXT_SIZE = 16\n","KEY_SIZE = 16\n","\n","# Training parameters.\n","ITERS_PER_ACTOR = 1\n","EVE_MULTIPLIER = 2  # Train Eve 2x for every step of Alice/Bob\n","# Train until either max loops or Alice/Bob \"good enough\":\n","MAX_TRAINING_LOOPS = 850000\n","BOB_LOSS_THRESH = 0.02  # Exit when Bob loss < 0.02 and Eve > 7.7 bits\n","EVE_LOSS_THRESH = 7.7\n","\n","# Logging and evaluation.\n","PRINT_EVERY = 200  # In training, log every 200 steps.\n","EVE_EXTRA_ROUNDS = 2000  # At end, train eve a bit more.\n","RETRAIN_EVE_ITERS = 10000  # Retrain eve up to ITERS*LOOPS times.\n","RETRAIN_EVE_LOOPS = 25  # With an evaluation each loop\n","NUMBER_OF_EVE_RESETS = 5  # And do this up to 5 times with a fresh eve.\n","# Use EVAL_BATCH\n","EVAL_BATCHES = 1"],"execution_count":10,"outputs":[{"output_type":"error","ename":"DuplicateFlagError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-63ed2092abfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0008\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Constant learning rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Batch size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;34m'Use of the keyword argument names (flag_name, default_value, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           'docstring) is deprecated, please use (name, default, help) instead.')\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_float\u001b[0;34m(name, default, help, lower_bound, upper_bound, flag_values, **args)\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m   \u001b[0mDEFINE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m   \u001b[0m_register_bounds_validator_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflag_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[0;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[1;32m     80\u001b[0m   \"\"\"\n\u001b[1;32m     81\u001b[0m   DEFINE_flag(_flag.Flag(parser, serializer, name, default, help, **args),\n\u001b[0;32m---> 82\u001b[0;31m               flag_values, module_name)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'learning_rate' is defined twice. First from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py.  Description from first occurrence: Constant learning rate"]}]},{"metadata":{"id":"KkOWv1-7NAGW","colab_type":"code","colab":{}},"cell_type":"code","source":[" def batch_of_random_bools(batch_size, n):\n","  \"\"\"Return a batch of random \"boolean\" numbers.\n","  Args:\n","    batch_size:  Batch size dimension of returned tensor.\n","    n:  number of entries per batch.\n","  Returns:\n","    A [batch_size, n] tensor of \"boolean\" numbers, where each number is\n","    preresented as -1 or 1.\n","  \"\"\"\n","\n","  as_int = tf.random_uniform(\n","      [batch_size, n], minval=0, maxval=2, dtype=tf.int32)\n","  expanded_range = (as_int * 2) - 1\n","  return tf.cast(expanded_range, tf.float32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wWns9UE0ND92","colab_type":"code","colab":{}},"cell_type":"code","source":["class AdversarialCrypto(object):\n","  \"\"\"Primary model implementation class for Adversarial Neural Crypto.\n","  This class contains the code for the model itself,\n","  and when created, plumbs the pathways from Alice to Bob and\n","  Eve, creates the optimizers and loss functions, etc.\n","  Attributes:\n","    eve_loss:  Eve's loss function.\n","    bob_loss:  Bob's loss function.  Different units from eve_loss.\n","    eve_optimizer:  A tf op that runs Eve's optimizer.\n","    bob_optimizer:  A tf op that runs Bob's optimizer.\n","    bob_reconstruction_loss:  Bob's message reconstruction loss,\n","      which is comparable to eve_loss.\n","    reset_eve_vars:  Execute this op to completely reset Eve.\n","  \"\"\"\n","\n","  def get_message_and_key(self):\n","    \"\"\"Generate random pseudo-boolean key and message values.\"\"\"\n","\n","    batch_size = tf.placeholder_with_default(FLAGS.batch_size, shape=[])\n","\n","    in_m = batch_of_random_bools(batch_size, TEXT_SIZE)\n","    in_k = batch_of_random_bools(batch_size, KEY_SIZE)\n","    return in_m, in_k\n","  \n","  def model(self, collection, message, key=None):\n","    \"\"\"The model for Alice, Bob, and Eve.  If key=None, the first fully connected layer\n","    takes only the message as inputs.  Otherwise, it uses both the key\n","    and the message.\n","    Args:\n","      collection:  The graph keys collection to add new vars to.\n","      message:  The input message to process.\n","      key:  The input key (if any) to use.\n","    \"\"\"\n","\n","    if key is not None:\n","      combined_message = tf.concat(axis=1, values=[message, key])\n","    else:\n","      combined_message = message\n","\n","    # Ensure that all variables created are in the specified collection.\n","    with tf.contrib.framework.arg_scope(\n","        [tf.contrib.layers.fully_connected, tf.contrib.layers.conv2d],\n","        variables_collections=[collection]):\n","\n","      fc = tf.contrib.layers.fully_connected(\n","          combined_message,\n","          TEXT_SIZE + KEY_SIZE,\n","          biases_initializer=tf.constant_initializer(0.0),\n","          activation_fn=None)\n","\n","      # Perform a sequence of 1D convolutions (by expanding the message out to 2D\n","      # and then squeezing it back down).\n","      fc = tf.expand_dims(fc, 2)\n","      # 2,1 -> 1,2\n","      conv = tf.contrib.layers.conv2d(\n","          fc, 2, 2, 2, 'SAME', activation_fn=tf.nn.sigmoid)\n","      # 1,2 -> 1, 2\n","      conv = tf.contrib.layers.conv2d(\n","          conv, 2, 1, 1, 'SAME', activation_fn=tf.nn.sigmoid)\n","      # 1,2 -> 1, 1\n","      conv = tf.contrib.layers.conv2d(\n","          conv, 1, 1, 1, 'SAME', activation_fn=tf.nn.tanh)\n","      conv = tf.squeeze(conv, 2)\n","      return conv\n","    \n","    def __init__(self):\n","      \n","      in_m, in_k = self.get_message_and_key()\n","      encrypted = self.model('alice', in_m, in_k)\n","      decrypted = self.model('bob', encrypted, in_k)\n","      eve_out = self.model('eve', encrypted, None)\n","\n","      self.reset_eve_vars = tf.group(\n","          *[w.initializer for w in tf.get_collection('eve')])\n","\n","      optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n","\n","      # Eve's goal is to decrypt the entire message:\n","      eve_bits_wrong = tf.reduce_sum(\n","          tf.abs((eve_out + 1.0) / 2.0 - (in_m + 1.0) / 2.0), [1])\n","      self.eve_loss = tf.reduce_sum(eve_bits_wrong)\n","      self.eve_optimizer = optimizer.minimize(\n","          self.eve_loss, var_list=tf.get_collection('eve'))\n","\n","      # Alice and Bob want to be accurate...\n","      self.bob_bits_wrong = tf.reduce_sum(\n","          tf.abs((decrypted + 1.0) / 2.0 - (in_m + 1.0) / 2.0), [1])\n","      # ... and to not let Eve do better than guessing.\n","      self.bob_reconstruction_loss = tf.reduce_sum(self.bob_bits_wrong)\n","      bob_eve_error_deviation = tf.abs(float(TEXT_SIZE) / 2.0 - eve_bits_wrong)\n","      # 7-9 bits wrong is OK too, so we squish the error function a bit.\n","      # Without doing this, we often tend to hang out at 0.25 / 7.5 error,\n","      # and it seems bad to have continued, high communication error.\n","      bob_eve_loss = tf.reduce_sum(\n","          tf.square(bob_eve_error_deviation) / (TEXT_SIZE / 2)**2)\n","\n","      # Rescale the losses to [0, 1] per example and combine.\n","      self.bob_loss = (self.bob_reconstruction_loss / (TEXT_SIZE + bob_eve_loss))\n","\n","      self.bob_optimizer = optimizer.minimize(\n","          self.bob_loss,\n","          var_list=(tf.get_collection('alice') + tf.get_collection('bob')))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VpBu5eBONQsO","colab_type":"code","colab":{}},"cell_type":"code","source":["def doeval(s, ac, n, itercount):\n","  \"\"\"Evaluate the current network on n batches of random examples.\n","  Args:\n","    s:  The current TensorFlow session\n","    ac: an instance of the AdversarialCrypto class\n","    n:  The number of iterations to run.\n","    itercount: Iteration count label for logging.\n","  Returns:\n","    Bob and Eve's loss, as a percent of bits incorrect.\n","  \"\"\"\n","\n","  bob_loss_accum = 0\n","  eve_loss_accum = 0\n","  for _ in xrange(n):\n","    bl, el = s.run([ac.bob_reconstruction_loss, ac.eve_loss])\n","    bob_loss_accum += bl\n","    eve_loss_accum += el\n","  bob_loss_percent = bob_loss_accum / (n * FLAGS.batch_size)\n","  eve_loss_percent = eve_loss_accum / (n * FLAGS.batch_size)\n","  print('%10d\\t%20.2f\\t%20.2f'%(itercount, bob_loss_percent, eve_loss_percent))\n","  sys.stdout.flush()\n","  return bob_loss_percent, eve_loss_percent"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0ykyVe3DNVnI","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_until_thresh(s, ac):\n","  for j in xrange(MAX_TRAINING_LOOPS):\n","    for _ in xrange(ITERS_PER_ACTOR):\n","      s.run(ac.bob_optimizer)\n","    for _ in xrange(ITERS_PER_ACTOR * EVE_MULTIPLIER):\n","      s.run(ac.eve_optimizer)\n","    if j % PRINT_EVERY == 0:\n","      bob_avg_loss, eve_avg_loss = doeval(s, ac, EVAL_BATCHES, j)\n","      if (bob_avg_loss < BOB_LOSS_THRESH and eve_avg_loss > EVE_LOSS_THRESH):\n","        print('Target losses achieved.')\n","        return True\n","  return False"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4O86Ior9NZES","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_and_evaluate():\n","  \"\"\"Run the full training and evaluation loop.\"\"\"\n","\n","  ac = AdversarialCrypto()\n","  init = tf.global_variables_initializer()\n","\n","  with tf.Session() as s:\n","    s.run(init)\n","    print('# Batch size: ', FLAGS.batch_size)\n","    print('# %10s\\t%20s\\t%20s'%(\"Iter\",\"Bob_Recon_Error\",\"Eve_Recon_Error\"))\n","\n","    if train_until_thresh(s, ac):\n","      for _ in xrange(EVE_EXTRA_ROUNDS):\n","        s.run(ac.eve_optimizer)\n","      print('Loss after eve extra training:')\n","      doeval(s, ac, EVAL_BATCHES * 2, 0)\n","      for _ in xrange(NUMBER_OF_EVE_RESETS):\n","        print('Resetting Eve')\n","        s.run(ac.reset_eve_vars)\n","        eve_counter = 0\n","        for _ in xrange(RETRAIN_EVE_LOOPS):\n","          for _ in xrange(RETRAIN_EVE_ITERS):\n","            eve_counter += 1\n","            s.run(ac.eve_optimizer)\n","          doeval(s, ac, EVAL_BATCHES, eve_counter)\n","        doeval(s, ac, EVAL_BATCHES, eve_counter)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dg0EiJWsNd2Y","colab_type":"code","colab":{}},"cell_type":"code","source":["def main(unused_argv):\n","  # Exit more quietly with Ctrl-C.\n","  signal.signal(signal.SIGINT, signal.SIG_DFL)\n","  train_and_evaluate()\n","\n","\n","  if __name__ == '__main__':\n","    tf.app.run()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A9Gks5HLNgU4","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}